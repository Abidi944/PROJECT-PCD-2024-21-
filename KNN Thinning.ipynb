{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendefinisikan direktori dataset asli dan dataset hasil deteksi tepi\n",
    "dataset_awal = \"Dataset/\"\n",
    "dataset_thinning = \"dataset_thinning\"\n",
    "\n",
    "# Memeriksa apakah folder dataset hasil sudah ada, jika tidak buat folder baru\n",
    "if not os.path.exists(dataset_thinning):\n",
    "    os.makedirs(dataset_thinning)\n",
    "\n",
    "# Mendapatkan daftar nama file gambar dalam dataset awal\n",
    "daftar_file = os.listdir(dataset_awal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sedan', 'Sport', 'SUV']\n"
     ]
    }
   ],
   "source": [
    "print(daftar_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi gray\n",
    "def Grayscale (image):\n",
    "    ker_gauss = np.ones((3,3))/9\n",
    "    image0 = image[:,:,0]\n",
    "    image1 = image[:,:,1]\n",
    "    image2 = image[:,:,2]\n",
    "    filteredimage0=cv.filter2D(image0,-1,ker_gauss)\n",
    "    filteredimage1=cv.filter2D(image1,-1,ker_gauss)\n",
    "    filteredimage2=cv.filter2D(image2,-1,ker_gauss)\n",
    "    return filteredimage0/3 + filteredimage1/3 + filteredimage2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Resize\n",
    "def resize (image):\n",
    "    res = cv.resize(image, (150, 150), interpolation=cv.INTER_NEAREST)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Threshold\n",
    "def Threshold(image):\n",
    "    matriks = np.array(image)\n",
    "    result = np.zeros(matriks.shape).astype(int)\n",
    "    for i in range(result.shape[0]):\n",
    "        for j in range(result.shape[1]):\n",
    "            if matriks[i,j] <= 128 : \n",
    "                result[i,j] = 255\n",
    "            else:\n",
    "                result[i,j] = 0\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thinning(image):\n",
    "    skeleton = np.zeros(image.shape, dtype=np.uint8)\n",
    "    prev = np.zeros(image.shape, dtype=np.uint8)\n",
    "    diff = None\n",
    "\n",
    "    while True:\n",
    "        prev[:] = skeleton\n",
    "        for step in range(1, 3):\n",
    "            for i in range(1, image.shape[0] - 1):\n",
    "                for j in range(1, image.shape[1] - 1):\n",
    "                    P2 = image[i-1, j]\n",
    "                    P3 = image[i-1, j+1]\n",
    "                    P4 = image[i, j+1]\n",
    "                    P5 = image[i+1, j+1]\n",
    "                    P6 = image[i+1, j]\n",
    "                    P7 = image[i+1, j-1]\n",
    "                    P8 = image[i, j-1]\n",
    "                    P9 = image[i-1, j-1]\n",
    "                    A = (P2 == 0 and P3 == 1) + (P3 == 0 and P4 == 1) + \\\n",
    "                        (P4 == 0 and P5 == 1) + (P5 == 0 and P6 == 1) + \\\n",
    "                        (P6 == 0 and P7 == 1) + (P7 == 0 and P8 == 1) + \\\n",
    "                        (P8 == 0 and P9 == 1) + (P9 == 0 and P2 == 1)\n",
    "                    B = P2 + P3 + P4 + P5 + P6 + P7 + P8 + P9\n",
    "                    m1 = step == 1 and (P2 * P4 * P6 == 0) and (P4 * P6 * P8 == 0)\n",
    "                    m2 = step == 2 and (P2 * P4 * P8 == 0) and (P2 * P6 * P8 == 0)\n",
    "                    if A == 1 and 2 <= B <= 6 and m1 and m2:\n",
    "                        skeleton[i, j] = 0\n",
    "                    else:\n",
    "                        skeleton[i, j] = image[i, j]\n",
    "        diff = np.sum(np.abs(skeleton - prev))\n",
    "        if diff == 0:\n",
    "            break\n",
    "    return skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Normalisasi\n",
    "def normalisasi(image):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    \n",
    "    normalized_image = (image - min_val) / (max_val - min_val)\n",
    "    uint8_image = (normalized_image * 255).astype(np.uint8)\n",
    "    \n",
    "    return uint8_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nama_file in daftar_file:\n",
    "\n",
    "#     # Membaca gambar dari dataset awal\n",
    "#     gambar_awal = cv.imread(os.path.join(dataset_awal, nama_file))\n",
    "\n",
    "#     # Mengubah gambar menjadi grayscale (Ganti pake fungsi manual)\n",
    "#     gambar_grayscale = cv.cvtColor(gambar_awal, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Melakukan resize (Ganti pake fungsi manual)\n",
    "#     gambar_kecil = resize (gambar_grayscale)\n",
    "#     # Melakukan thresholding (Ganti pake fungsi manual)\n",
    "#     gambar_threshold = Threshold (gambar_kecil)\n",
    "#     # Melakukan deteksi tepi metode Sobel (Ganti pake fungsi manual)\n",
    "#     gambar_tepi = thinning (gambar_threshold)\n",
    "#     # Melakukan normalisasi citra (Ganti pake fungsi manual)\n",
    "#     gambar_normal = normalisasi (gambar_tepi)\n",
    "\n",
    "#     cv.imwrite(os.path.join(dataset_thinning, nama_file), gambar_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat data gambar\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for folder in os.listdir(data_dir):\n",
    "        label = folder\n",
    "        for image_filename in os.listdir(os.path.join(data_dir, folder)):\n",
    "            image_path = os.path.join(data_dir, folder, image_filename)\n",
    "            image = Image.open(image_path).resize((32, 32))\n",
    "            image_data = np.array(image)\n",
    "            images.append(image_data.flatten())\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data('dataset_thinning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi data menjadi training dan testing (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat model KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melatih model dengan data training\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan prediksi pada data testing\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung akurasi model\n",
    "accuracy = np.mean(y_pred == y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model KNN: 36.19631901840491 %\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan hasil akurasi\n",
    "print(\"Akurasi model KNN:\", accuracy, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
